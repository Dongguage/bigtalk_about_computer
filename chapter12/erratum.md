## 第十二章 机器学习与人工智能

错误：

| 页码 | 具体位置               | 原内容 | 修改后的内容 | 贡献者 |
| ---- | ---------------------- | ------ | ------------ | ------ |
| 脑图   |靠上 | 分线性/线性变换 | 非线性/线性变换 | -      |
|P1430|左下|a=b=0|a=1,b=0||
|P1430|左下倒数第7行|学习率|加粗处理||
|P1431|第6行|拟合函数|加粗处理||
|P1437|图12-11 图题|图12-11 Sigmoid函数的特性示意|图12-11 Sigmoid函数的特性示意（可以看到W调整折弯处的陡峭程度，绝对值越大越陡峭。b与W的比值调整的则是左右平移距离）||
|P1438|图12-14|太靠边以至于+号没了|往右靠露出“+”|
|P1441|左中|硬叫它激励函数就是误导了|硬叫它激活函数就是误导了||
|P1447|左下角提示框|预先连号|预先连好||
|P1455|12.6标题下方插入一段||同一类物品的图片，有时候直接看的话，会有很大区别，所以将它们直接输入到DNN里训练，识别率会比较低。需要提升泛化识别能力。那就意味着需要针对看上去不同的同一类物品的图片，提取出出共性特征，提高泛化抽象能力。||
|P1485|右中|FPGA，A斜体了|FPGA||

改进：

| 页码 | 具体位置               | 原内容 | 修改后的内容 | 贡献者 |
| ---- | ---------------------- | ------ | ------------ | ------ |
|P1437|图12-11 图题|图12-11 Sigmoid函数的特性示意|图12-11 Sigmoid函数的特性示意（可以看到W调整折弯处的陡峭程度，绝对值越大越陡峭。b与W的比值调整的则是左右平移距离）||
|P1438  | 右中| 在乐高玩具一段下插入一段 | 注意，上文中采用的思路是，用S函数来把一条构造好直线处理成弯曲线，然后用这条弯曲线与原始的、用作分类样点的直线相乘，相乘的目的是把原始分类直线上不需要的区段平抑掉。然后将平抑了非需要区段的所有原始直线相加，便成了最终的曲线。而我们现在要做的是，直接用S函数处理好的弯曲线拼接出目标曲线，不需要原始直线，或者说这些弯曲线就是原始直线。  | 冬瓜哥     |
|P1440|左中|而如果用这些参数来画曲线的话发现真的会画出一条类似的曲线。|而如果用这些参数来画曲线的话发现真的会画出一条类似的曲线。也就是说，整个机器学习的思路就是将各种待识别和分类的实体抽象成在平面上画曲线的数学几何手段。|冬瓜哥|
|P1440|左中|在上面这段之后插入一段|至此，针对分类这个问题，我们有了三个不同的数学模型：直线+与或非处理模型、原始直线与用S函数处理之后的弯曲线相乘平抑不需要区段然后拼接的处理模型、直接用S函数处理后的弯曲线拼接的处理模型。这三种模型对应了不同的数学公式，但是最后都能得到近似结果。这好像成了一个数学问题，没错的。这就像求π可以有多种数学手段一样。最终人们常用的还是上述第三种模型。因为从图12-22中可以明显看出，该模型对应的运算单一，就是多项WiS(Wmx+b)相加，对应的运算就是单纯的乘加。这样的话，采用专用电路去实现就非常方便和高效。|冬瓜哥|
|P1441|P1441页附近，任意地点新插入一个思考框||如果目标模型函数实际上只是一条简单的直线，还需要神经网络这么复杂的东西么？直接给出Y=aX+b让机器来求解a和b不就可以了么？是的，但是问题是你一开始可能并不知道这一堆样本点之间到底呈现一种什么关系，老一辈统计学专家可以根据各种手段预估出一个合适的可能函数关系，但是新一辈后浪们显然不愿意动这个脑子，普遍期待一种无脑化的穷举迭代，让机器自己学习出来：“哦，原来叠加完了就是一条直线啊！”，达到这种效果。这就是机器学习的奥妙所在，机器可以自动学习出规律来，但是学习出来的规律，是一种拟合，也就是用乐高积木搭建出来的形状，而老统计学手法是真的用石膏做了一个一次成型的整体模型出来，虽然都是拟合，但是前者是用一堆小零件任意堆叠，而后者则是每次开一个新模具。||
|P1441|任意地点新插入一个思考框||可以引申思考一下，对于逻辑分类模型曲线，曲线上某个线段上升下降幅度较大，则对应该线段的W参数数值高，因为W对应着线段的纵方向上的幅度值系数，所以Wx+b的值就高，就越激活；同时，如国某个线段更陡峭，说明S(Wx+b)中的W绝对值也就越大，那对应的神经元也是强激活状态。感性上讲，幅值大，变化陡峭的地方，的确就是触发神经敏感的地方。在后面的图象识别模型中，你会对“激活”二字由更深刻的理解。至于在神经网络里的具体哪个神经元激活，这个神经元的输出线段零件又最终被哪个或者哪些下游神经元用作输入来叠加更复杂的线段，这个主要与各个参数的初始值有关，迭代的出发点不同，最终被激活的神经元位置和关系也就不同。这也是不同的人大脑回路各不相同的原因。||
|P1455|12.6标题下方插入一段||同一类物品的图片，有时候直接看的话，会有很大区别，所以将它们直接输入到DNN里训练，识别率会比较低。需要提升泛化识别能力。那就意味着需要针对看上去不同的同一类物品的图片，提取出出共性特征，提高泛化抽象能力。||

